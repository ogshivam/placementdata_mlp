# -*- coding: utf-8 -*-
"""first.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14DbJW5rTigFB0JQ2Iew81Kzl-V5eqSge

Importing all the necessary libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.data import TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.svm import SVC
import pickle

"""Data Loading"""

#loading the dataset
df = pd.read_csv('placementdata.csv')

# Display first few rows
df.head()

# Check for missing values
df.isnull().sum()

df.columns

df.describe()

# Check data types
df.info()

df.ExtracurricularActivities.unique()

df.PlacementStatus.unique()

df.PlacementTraining.unique()

# Check class distribution
df["PlacementStatus"].value_counts()

"""Data Preprocessing"""

#encode the categorical variables
categorical_columns = ['PlacementTraining', 'ExtracurricularActivities', 'PlacementStatus']
label_encoder = LabelEncoder()
df[categorical_columns] = df[categorical_columns].apply(label_encoder.fit_transform)

df.head()

"""Data Visualization"""

plt.figure(figsize=(6, 4))
sns.countplot(x=df["PlacementStatus"], palette=["red", "green"])
plt.title("Placement Status Distribution")
plt.xlabel("Placement Status (0 = Not Placed, 1 = Placed)")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

plt.figure(figsize=(12,6))
sns.boxplot(data=df[["CGPA", "AptitudeTestScore", "SSC_Marks", "HSC_Marks"]])
plt.title("Boxplot of Key Features")
plt.show()

sns.pairplot(df, hue="PlacementStatus", diag_kind="kde")
plt.show()

plt.figure(figsize=(8,5))
sns.violinplot(x=df["PlacementStatus"], y=df["CGPA"], palette=["red", "green"])
plt.title("CGPA Distribution for Placement Status")
plt.show()

plt.figure(figsize=(12,5))
sns.countplot(x=df["PlacementTraining"].astype(str), hue=df["PlacementStatus"].astype(str), palette=["red", "green"])
plt.title("Placement Training vs Placement Status")
plt.show()

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

sns.countplot(x=df["Internships"].astype(str), hue=df["PlacementStatus"].astype(str), ax=axes[0], palette=["red", "green"])
sns.countplot(x=df["Projects"].astype(str), hue=df["PlacementStatus"].astype(str), ax=axes[1], palette=["red", "green"])
sns.countplot(x=df["ExtracurricularActivities"].astype(str), hue=df["PlacementStatus"].astype(str), ax=axes[2], palette=["red", "green"])

plt.tight_layout()
plt.show()

"""Rest Data Preprocessing"""

# Encode categorical variables
label_encoder = LabelEncoder()
df["PlacementTraining"] = label_encoder.fit_transform(df["PlacementTraining"])
df["ExtracurricularActivities"] = label_encoder.fit_transform(df["ExtracurricularActivities"])
df["PlacementStatus"] = label_encoder.fit_transform(df["PlacementStatus"])  # 1 = Placed, 0 = NotPlaced

# Features & Target
X = df.drop(["StudentID", "PlacementStatus"], axis=1)  # Drop ID column
y = df["PlacementStatus"]

# Feature Scaling
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

"""Model Training"""

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Initialize models
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC()
}

# Train and evaluate models
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"Results for {name}:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    print("-" * 50)

#Tuning Logistic Regression
param_grid_lr = {
    "C": [0.01, 0.1, 1, 10, 100],  # Regularization strength
    "solver": ["liblinear", "lbfgs"]  # Different solvers
}

grid_search_lr = GridSearchCV(LogisticRegression(max_iter=500), param_grid_lr, cv=5, scoring="accuracy", n_jobs=-1)
grid_search_lr.fit(X_train, y_train)

print("Best parameters for Logistic Regression:", grid_search_lr.best_params_)
best_lr = grid_search_lr.best_estimator_
print("Best Logistic Regression:", best_lr)

#Tuning Random Forest
param_grid_rf = {
    "n_estimators": [50, 100, 200],
    "max_depth": [5, 10, 20, None],
    "min_samples_split": [2, 5, 10]
}

grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring="accuracy", n_jobs=-1)
grid_search_rf.fit(X_train, y_train)

print("Best parameters for Random Forest:", grid_search_rf.best_params_)
best_rf = grid_search_rf.best_estimator_
print("Best Random Forest:", best_rf)

#Tuning SVM
param_grid_svm = {
    "C": [0.1, 1, 10, 100],
    "kernel": ["linear", "rbf", "poly"],
    "gamma": ["scale", "auto"]
}

grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring="accuracy", n_jobs=-1)
grid_search_svm.fit(X_train, y_train)

print("Best parameters for SVM:", grid_search_svm.best_params_)
best_svm = grid_search_svm.best_estimator_
print("Best SVM:", best_svm)

#stratified kfold cross validation
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

models = {
    "Logistic Regression": LogisticRegression(C=1, max_iter=500, solver='liblinear'),
    "Random Forest": RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=200),
    "SVM": SVC(C=1, gamma='auto', probability=True)  # probability=True for AUC calculation
}

for name, model in models.items():
    acc_scores = cross_val_score(model, X, y, cv=kf, scoring="accuracy")
    f1_scores = cross_val_score(model, X, y, cv=kf, scoring="f1")
    auc_scores = cross_val_score(model, X, y, cv=kf, scoring="roc_auc")

    print(f"\n{name} - Cross-Validation Results:")
    print(f"Mean Accuracy: {acc_scores.mean():.4f} ± {acc_scores.std():.4f}")
    print(f"Mean F1-score: {f1_scores.mean():.4f} ± {f1_scores.std():.4f}")
    print(f"Mean AUC Score: {auc_scores.mean():.4f} ± {auc_scores.std():.4f}")

#model evaluation
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else model.decision_function(X_test)

    print(f"\nResults for {name}:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))

    auc_score = roc_auc_score(y_test, y_pred_proba)
    print(f"ROC AUC Score: {auc_score:.4f}")
    print("-" * 50)

#ensemble learning
from sklearn.ensemble import StackingClassifier

stacked_model = StackingClassifier(
    estimators=[
        ('lr', LogisticRegression(C=1, solver='liblinear')),
        ('rf', RandomForestClassifier(n_estimators=200, max_depth=10)),
        ('svm', SVC(C=1, gamma='auto', probability=True))
    ],
    final_estimator=LogisticRegression()
)
stacked_model.fit(X_train, y_train)

y_pred_stacked = stacked_model.predict(X_test)
print("Stacking Classifier Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_stacked))
print(classification_report(y_test, y_pred_stacked))
print("-" * 50)

"""Building a multilayer perceptron model"""

# Define the MLP model
class MLP(nn.Module):
    def __init__(self, input_size):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(0.3)

        self.fc2 = nn.Linear(128, 64)
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(0.3)

        self.fc3 = nn.Linear(64, 2)  # 2 classes (Binary Classification)
        self.softmax = nn.Softmax(dim=1)  # Output probabilities

    def forward(self, x):
        x = self.relu1(self.fc1(x))
        x = self.dropout1(x)
        x = self.relu2(self.fc2(x))
        x = self.dropout2(x)
        x = self.softmax(self.fc3(x))
        return x

# Convert dataset to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)

# Convert y_train and y_test to NumPy arrays before converting to tensors
y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)
y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)

# Initialize model
input_size = X_train_tensor.shape[1]
model = MLP(input_size)

criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks
optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer

# Training loop
epochs = 50
batch_size = 32

for epoch in range(epochs):
    optimizer.zero_grad()  # Zero gradients
    outputs = model(X_train_tensor)  # Forward pass
    loss = criterion(outputs, y_train_tensor)  # Compute loss
    loss.backward()  # Backpropagation
    optimizer.step()  # Update weights

    if (epoch + 1) % 10 == 0:  # Print every 10 epochs
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}")

# Model evaluation
with torch.no_grad():
    y_pred_logits = model(X_test_tensor)
    y_pred = torch.argmax(y_pred_logits, axis=1)

accuracy = (y_pred == y_test_tensor).float().mean().item()
print(f"Test Accuracy: {accuracy:.4f}")

# Confusion Matrix
with torch.no_grad():
    y_pred_logits = model(X_test_tensor)
    y_pred = torch.argmax(y_pred_logits, axis=1)
    cm = confusion_matrix(y_test_tensor, y_pred)
    print("Confusion Matrix:")
    print(cm)

# Save as CSV files
pd.DataFrame(X_train).to_csv("X_train.csv", index=False)
pd.DataFrame(y_train).to_csv("y_train.csv", index=False)
pd.DataFrame(X_test).to_csv("X_test.csv", index=False)
pd.DataFrame(y_test).to_csv("y_test.csv", index=False)

print("Datasets saved as CSV files!")

"""Saving all the models"""

# Dictionary to store the trained models
models = {
    "logistic_regression": best_lr,
    "svc": best_svm,
    "random_forest": best_rf,
    "stacking_classifier": stacked_model
}

# Save models to a file
with open("trained_models.pkl", "wb") as f:
    pickle.dump(models, f)

print("Models saved successfully!")